{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "910be5d2-b97b-4bb1-947b-bec880f6cb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 mesh files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing meshes: 100%|████████████████████| 1000/1000 [00:46<00:00, 21.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 1000 samples to /Users/ivantothrohonyi/Documents/cs2241-finalproj/pu1k_uniform256_uniform1024_from_meshes.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "script_dir = os.getcwd()\n",
    "root_dir = os.path.join(script_dir, 'data', 'PU1K_raw_meshes', 'ShapeNetCore.v2.subsample')\n",
    "output_h5_path = os.path.join(script_dir, 'pu1k_uniform256_uniform1024_from_meshes.h5')\n",
    "input_size = 256\n",
    "gt_size = 1024\n",
    "\n",
    "# === SAMPLING FUNCTION ===\n",
    "def uniform_sample(mesh, n):\n",
    "    \"\"\"\n",
    "    Uniformly sample `n` points from a mesh surface.\n",
    "    \"\"\"\n",
    "    points, _ = trimesh.sample.sample_surface(mesh, n)\n",
    "    return points\n",
    "\n",
    "# === DATA PROCESSING ===\n",
    "input_point_clouds = []\n",
    "gt_point_clouds = []\n",
    "\n",
    "# Traverse all subdirectories and .off files\n",
    "mesh_files = []\n",
    "for subdir, _, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.off'):\n",
    "            mesh_files.append(os.path.join(subdir, file))\n",
    "\n",
    "print(f\"Found {len(mesh_files)} mesh files.\")\n",
    "\n",
    "# Process each mesh\n",
    "for mesh_path in tqdm(mesh_files, desc=\"Processing meshes\"):\n",
    "    try:\n",
    "        mesh = trimesh.load(mesh_path, force='mesh')\n",
    "        input_pc = uniform_sample(mesh, input_size)\n",
    "        gt_pc = uniform_sample(mesh, gt_size)\n",
    "        \n",
    "        input_point_clouds.append(input_pc.astype(np.float32))\n",
    "        gt_point_clouds.append(gt_pc.astype(np.float32))\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {mesh_path}: {e}\")\n",
    "\n",
    "# Convert lists to arrays\n",
    "input_array = np.array(input_point_clouds, dtype=np.float32)  # shape (N, 256, 3)\n",
    "gt_array = np.array(gt_point_clouds, dtype=np.float32)        # shape (N, 1024, 3)\n",
    "\n",
    "# === SAVE TO HDF5 ===\n",
    "with h5py.File(output_h5_path, 'w') as f:\n",
    "    f.create_dataset('poisson_256', data=input_array)     # Compatible with PU-GCN\n",
    "    f.create_dataset('poisson_1024', data=gt_array)\n",
    "\n",
    "print(f\"✅ Saved {len(input_array)} samples to {output_h5_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc085e43-5488-41a0-aae7-137a5574289d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 mesh files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing meshes:  87%|██████████████████▎  | 872/1000 [00:51<00:09, 13.74it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "script_dir = os.getcwd()\n",
    "\n",
    "root_dir = os.path.join(script_dir, 'data', 'PU1K_raw_meshes', 'ShapeNetCore.v2.subsample')\n",
    "output_h5_path = os.path.join(script_dir, 'pu1k_fps256_uniform1024_from_meshes.h5')\n",
    "input_size = 256\n",
    "gt_size = 1024\n",
    "oversample_factor = 10  # for initial dense sampling\n",
    "\n",
    "# === SAMPLING FUNCTIONS ===\n",
    "def uniform_sample(mesh, n):\n",
    "    points, _ = trimesh.sample.sample_surface(mesh, n)\n",
    "    return points\n",
    "\n",
    "def farthest_point_sampling(points, n_samples):\n",
    "    N = points.shape[0]\n",
    "    sampled_indices = np.zeros(n_samples, dtype=int)\n",
    "    distances = np.full(N, np.inf)\n",
    "    \n",
    "    sampled_indices[0] = np.random.randint(N)\n",
    "    selected = points[sampled_indices[0]]\n",
    "    \n",
    "    for i in range(1, n_samples):\n",
    "        dist = np.linalg.norm(points - selected, axis=1)\n",
    "        distances = np.minimum(distances, dist)\n",
    "        sampled_indices[i] = np.argmax(distances)\n",
    "        selected = points[sampled_indices[i]]\n",
    "    \n",
    "    return points[sampled_indices]\n",
    "\n",
    "# === DATA PROCESSING ===\n",
    "input_point_clouds = []\n",
    "gt_point_clouds = []\n",
    "\n",
    "mesh_files = []\n",
    "for subdir, _, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.off'):\n",
    "            mesh_files.append(os.path.join(subdir, file))\n",
    "\n",
    "print(f\"Found {len(mesh_files)} mesh files.\")\n",
    "\n",
    "for mesh_path in tqdm(mesh_files, desc=\"Processing meshes\"):\n",
    "    try:\n",
    "        mesh = trimesh.load(mesh_path, force='mesh')\n",
    "        \n",
    "        # Step 1: Sample a dense cloud for FPS to act on\n",
    "        dense_points, _ = trimesh.sample.sample_surface(mesh, input_size * oversample_factor)\n",
    "        \n",
    "        # Step 2: FPS for input\n",
    "        input_pc = farthest_point_sampling(dense_points, input_size)\n",
    "        \n",
    "        # Step 3: Uniform sampling for GT\n",
    "        gt_pc = uniform_sample(mesh, gt_size)\n",
    "        \n",
    "        input_point_clouds.append(input_pc.astype(np.float32))\n",
    "        gt_point_clouds.append(gt_pc.astype(np.float32))\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {mesh_path}: {e}\")\n",
    "\n",
    "input_array = np.array(input_point_clouds, dtype=np.float32)\n",
    "gt_array = np.array(gt_point_clouds, dtype=np.float32)\n",
    "\n",
    "# === SAVE TO HDF5 ===\n",
    "with h5py.File(output_h5_path, 'w') as f:\n",
    "    f.create_dataset('poisson_256', data=input_array)     # Name stays the same for compatibility\n",
    "    f.create_dataset('poisson_1024', data=gt_array)\n",
    "\n",
    "print(f\"✅ Saved {len(input_array)} samples to {output_h5_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2daf8-5de9-41ea-b257-8ae01a6b8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "script_dir = os.getcwd()\n",
    "root_dir = os.path.join(script_dir, 'data', 'PU1K_raw_meshes', 'ShapeNetCore.v2.subsample')\n",
    "output_h5_path = os.path.join(script_dir, 'pu1k_pugcnstyle_256from1024_poisson.h5')\n",
    "input_size = 256\n",
    "gt_size = 1024\n",
    "\n",
    "# === DATA BUFFERS ===\n",
    "input_point_clouds = []\n",
    "gt_point_clouds = []\n",
    "\n",
    "# === GET ALL MESH FILES ===\n",
    "mesh_files = []\n",
    "for subdir, _, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.off'):\n",
    "            mesh_files.append(os.path.join(subdir, file))\n",
    "\n",
    "print(f\"Found {len(mesh_files)} mesh files.\")\n",
    "\n",
    "# === PROCESS EACH MESH ===\n",
    "for mesh_path in tqdm(mesh_files, desc=\"Generating PU-GCN-style samples\"):\n",
    "    try:\n",
    "        mesh = trimesh.load(mesh_path, force='mesh')\n",
    "\n",
    "        # Step 1: Poisson-disk sample 1024 points for GT\n",
    "        gt_pc, _ = trimesh.sample.sample_surface_even(mesh, gt_size)\n",
    "\n",
    "        # Step 2: Randomly choose 256 points as input (subset of GT)\n",
    "        indices = np.random.choice(gt_pc.shape[0], input_size, replace=False)\n",
    "        input_pc = gt_pc[indices]\n",
    "\n",
    "        # Save results\n",
    "        input_point_clouds.append(input_pc.astype(np.float32))\n",
    "        gt_point_clouds.append(gt_pc.astype(np.float32))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {mesh_path}: {e}\")\n",
    "\n",
    "# === SAVE TO HDF5 ===\n",
    "input_array = np.array(input_point_clouds, dtype=np.float32)\n",
    "gt_array = np.array(gt_point_clouds, dtype=np.float32)\n",
    "\n",
    "with h5py.File(output_h5_path, 'w') as f:\n",
    "    f.create_dataset('poisson_256', data=input_array)     # PU-GCN compatibility\n",
    "    f.create_dataset('poisson_1024', data=gt_array)\n",
    "\n",
    "print(f\"✅ Saved {len(input_array)} samples to {output_h5_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
